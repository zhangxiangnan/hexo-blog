layout: title
title: kafka的适用场合
date: 2017-02-14 16:06:02
tags:
- kafka
categories:
- 译
- kafka
---

kafka的适用场合
<!-- more -->

### Kafka的常见应用场合

#### 消息系统
  Kafka完全可以替换传统消息服务器。使用消息系统有很多原因，解耦消息生产者和处理过程，缓存未处理的消息等。对比大多数消息系统，Kafka有更高的吞吐量，而且基于分片构建，有副本机制，有容错机制，对于构建大规模可扩展的消息处理程序是不错的选择。
  在我们的经验中，消息的使用往往相对低延迟，但需要很低的终端到终端的延迟，且经常依赖于Kafka提供强大的持久性保证。

  在消息系统领域，Kafka相较于传统消息系统如ActiveMq、RabbitMQ。

#### 网站活动追踪

  Kafka一开始是用来构建用户行为追踪流水线作为一系列实时的发布订阅模型的订阅源。这就是说网站活动（页面浏览、搜索、其他用户产生的行为动作）按着一个活动类型一个主题被发布到中央主题。这些订阅源可以用来消费用于一系列用途如实时处理、实时监控、加载数据到Hadoop或线下数据仓库系统以便于线下处理和报表。
  活动行为追踪常常数据量非常大，因为每一次用户浏览页面都产生许多活动信息。

#### Metrics
  Kafka经常用来分析运行时的监控数据。这涉及聚合来自分布式应用程序的统计数据来产生运行数据的几种馈送。

#### 日志聚合Log Aggregation
  很多人使用Kafka进行日志聚合的方案。日志聚合通常从服务器收集物理日志文件，并将其集中起来（文件服务器或者可能HDFS）处理。Kafka抽象了文件的细节，并将日志或事件数据更清晰地抽象为消息流。这允许更低延迟地处理，更容易支持多数据源和分布式数据消费。相比于以日志为中心的系统如Scribe或者Flume，Kafka提供了同样出色的性能，更强的持久性保证及更低的端到端延迟。

#### 流处理Stream Processing

  很多Kafka用户在由多个阶段组成的处理流水线中处理数据，其中原始数据从Kafka主体消费，接着聚合，丰富，或转换到新主题以便于进一步消费或后续处理。如，一个推荐新闻文章的流水线可能先从RSS订阅源抓取文章内容，将其发布到名为“articles”的主题；进一步处理可能是规范化或者对内容去重，然后发布到清理后的内容到一个新主题；最后的处理阶段可能是尝试推荐内容给用户。这样的处理流水线就是基于不同的主题进行实时数据流的处理。从Kafka的0.10.0.0版本处理，一个轻量级但强大的流处理库为Kafka Streams可用来执行上述的数据处理。除了Kafka Streams，也可选择其他开源流处理工具如Apache Storm和Apache Samza。

#### 事件源Event Sourcing
  事件源是一种应用程序设计风格，其中状态变化记录为按时间排序的记录序列。Kafka支持非常大的存储日志数据，是构建于这种风格的应用程序极好的后端。

#### 提交日志Commit Log
  Kafka可以作为分布式系统的一种外部提交日志。该日志有助于各节点间备份数据，以及故障节点重新恢复数据时充当重新同步机制。Kafka的日志压缩特性有助于支持该用途。在这点上，Kafka类似于Apache的Zookeeper项目的作用。
