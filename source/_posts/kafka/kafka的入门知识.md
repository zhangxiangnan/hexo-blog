layout: title
title: kafka的入门知识
date: 2017-01-09 17:17:02
tags:
- kafka
categories:
- 译
- kafka
---

kafka的入门知识
<!-- more -->

### kafka是一个分布式的流式传输平台
分布式流平台应该具有的三个特征：
  - 可以发布和订阅流记录流，这点类似于消息队列或者企业级消息系统
  - 可以以容错方式存储记录流
  - 可以当产生记录流时进行处理.

kafka的优势
kafka用于2大类应用程序：
  - 构建可靠地在系统或应用程序之间获取数据的实时流数据流水线
  - 构建对数据流进行变换或反应的实时流应用程序

几个概念：
Kafka作为集群运行在一个或者多个机器上
Kafka集群以称为主题的类别存储记录流。
每个记录由一个键，一个值和一个时间戳组成。

Kafka有四个核心API：
  - Producer API允许应用程序发布记录流到一个或多个Kafka主题
  - Consumer API允许应用程序订阅一个或多个主题，并处理为其生成的记录流.
  - Steams API允许应用程序充当流处理器，从一个或多个主题消费输入流，然后产生输出流到一个或多个输出主题，高效地转换输入流到输出流。
  - Connector API允许构建和运行可重用的生产者或消费者，将Kafka主题连接到现有应用程序或数据系统。例如，关系数据库的Connector连接器可能捕获对表的每个更改。

  ![kafka-apis](
  http://kafka.apache.org/0101/images/kafka-apis.png)

Kafka中，客户端和服务端的通讯使用一个简单的，高性能的，语言无关的TCP协议。该协议有版本控制，并保持与旧版本的向后兼容性。同时，提供了很多种语言的Kafka客户端。

### 主题Topics和日志Logs
Kafka为记录流提供的核心抽象便是主题（topic）.
主题是发布记录的类别或者feed名称。Kafka的主题总是支持多个消费者的，即一个主题可以拥有0个、1个或者多个订阅者来订阅发送到该主题的数据。

对于每个主题，Kafka集群维护了一个分区日志如下图：
![log_anatomy](
http://kafka.apache.org/0101/images/log_anatomy.png)

每一个分区是一个有序的、不可变的记录序列，不断地追加到结构化提交日志。分区中的每条记录都被赋予了一个顺序的id号，称作offset偏移量，偏移量在某个分区内唯一标示每条记录。

Kafka集群保留所有已发布的记录，无论是否已经被消费。当然保留所有数据也不现实，kafka提供两种方式来删除数据，一种通过配置来定义数据的保留时间，另一种通过配置分区文件大小限制。例如，如果设置保留策略为2天，则一条记录在被发布后的2天之内，是可以被消费的，一旦2天过后则被丢弃来达到释放空间的目的。Kafka的性能和数据的大小密切相关，和将数据存储多长时间无太大关系.

![log_consumer](
http://kafka.apache.org/0101/images/log_consumer.png)

事实上，每个消费者保留的唯一元数据是该消费者在日志中的偏移或位置。这种偏移由消费者控制，通常消费者在读取记录时线性地提前其偏移，但是实际上，由于消费者控制着位置的值，所以它可以以喜欢的任何顺序来消费数据。例如，一个消费者可以将偏移量的值减小来重复处理以前的数据，或者跳过最近的记录从“现在”开始消费数据。

这些功能的组合使kafka的消费者非常轻量级，消费者来来去去，对集群和其他消费者却没什么太多影响。如，你可以通过kafka命令行工具的tail命令来获取任何主题的记录，却无需更改任何现有用户使用的内容。

日志的分区设计有几个目的。首先分区使日志可以增加到超出单台服务器的容量。首先，它们允许日志扩展到适合单个服务器的大小。每个单独的分区必须适合托管它的服务器，但主题可能有许多分区，因此它可以处理任意数量的数据。第二，为了并行性

### 分布式
日志的分区分布在kafka集群中的服务器上，每个服务器处理数据并请求共享分区。每个分区都使用可配置数量的服务器进行复制，以实现容错。

每个分区都有一台机器充当leader，0或者多台机器充当followers。leader处理所有的针对该分区的读和写请求，followers则被动同步leader的数据。若leader宕机，则kafka自动选取一个followers来充当leader。每个服务器都充当某个分区的leader，同时，又充当剩下分区的follower，这样实现集群的负载均衡。

### 生产者Producers
生产者发布数据到他们选择发布的主题上。生产者决定哪条记录发布到主题内的哪个分区上，实现这个功能可以通过简单轮询或者通过语法层面的分区函数（如根据记录里的某个关键字段）来实现负载均衡。

### 消费者Consumers
消费者使用一个消费者组名称consumer group name来标记自己，发布到主题的每个记录针对订阅该主题的每个消费组只会发送给其中一个消费者实例（消费者实例可以是在单独的进程或者单独的机器上）。
如果所有的消费者实例有相同的消费组，这样数据将在这些消费者实例中很好地负载均衡。
如果所有的消费者实例都有着不同的消费组，这样每条数据记录都会被广播到所有的消费者实例中。    

![consumer-groups](http://kafka.apache.org/0101/images/consumer-groups.png)

如图，两台服务器组成的kafka集群，托管有四个分区(p0~p3)，与2个消费组。消费组A有2个消费者实例，消费组B有4个消费者实例。

通常情况下，一个主题有少量的消费组，可以理解为“逻辑上的订阅者”。为了扩展和容错，每个消费组里包含多个消费者实例。这就和发布-订阅模型很像，只不过kafka的一个订阅者是一个由很多实例组成的集群而不是单个进程。

在Kafka中实现消费的方式是通过在消费者实例上划分日志中的分区，使得每个实例在任何时间点是分区的“公平共享”的独占消费者。维持消费组内的消费实例与分区关系的过程是通过kafka协议动态完成的。如果新的消费实例加入消费组，他们会从组内的其他消费实例的手中接管一些分区；如果一个消费者实例死掉，它负责的分区会被分派到其他尚存的消费者实例中。

Kafka只提供一个分区内记录的总顺序，而不是主题中的不同分区之间，即不保证一个主题内不同分区的数据间的顺序关系。每个分区的顺序性结合按键分割数据的特性已经能满足大部分的程序需要。然而，如果你需要对记录进行总排序，可以使用只有一个分区的主题来实现，这意味着每个消费组内也只能有一个消费者实例。

### 保证
Kafka提供了如下保证：
  - 生产者发送到特定主题分区的消息将按照发送时的顺序进行追加。即，如果记录M1和M2都是被同一个生产者发送，且M1先发送，这样M1拥有比M2小的偏移量，而且在日志文件里也出现的比M2早。
  - 一个消费者实例按照记录在日志文件里存储的顺序消费数据。
  - 针对副本个数设置为N的主题，kafka可以容忍N-1个服务器故障而不丢失任何提交到日志文件的任何记录。

### Kafka作为消息系统Messaging System
Kafka流的概念 VS 传统企业级消息系统：

1、传统消息系统有2个模型：队列和发布-订阅模型。针对队列，一组消费者从一个服务器读取数据，每一条记录只被其中的一个消费者消费；针对发布-订阅模型，每条记录被广播到所有消费者。这2个模型都有其优势和劣势。队列允许你分割数据的处理到多个消费者实例，让你可以扩展处理过程，但不支持多个消费者组,因为一旦一个进程消费了数据数据便不可再被消费。发布订阅允许你广播数据到多个订阅者，但是不能够扩展处理过程因为每条记录都被发送到每一个订阅者。

由此，kafka产生了消费组的概念，和队列一样，消费组让你可以分割处理过程到一系列进程去处理（消费组的成员）。和订阅发布类似，消费组让你可以广播信息到多个消费组。

Kafka模型的优势是每个主题都有着两个特性，可以扩展处理过程同时支持多订阅者，没有必要非得像传统消息系统一样非得选择队列或者订阅发布模型。

2、Kafka相比传统消息系统也有着更强的顺序保证：
传统队列在服务器端按顺序保留记录，如果多个消费者从队列里消费数据，服务端按照他们存储的顺序分发记录，记录被异步传递到消费者，所以记录可能到达不同的消费者时丢失了顺序。这意味着存在并行消费时，记录的顺序在被多个消费者消费时的顺序和其存储顺序则不一致。消息系统通常使用一个叫做独占消费者的概念来解决这个问题，独占消费者只允许一个进程来从队列里消费数据，但这意味着处理过程没有并行性。

Kafka做得更好。通过在主题内部具有并行性的概念（分区），kafka可以在多个消费者进程间保证顺序和负载均衡。通过将主题内的分区分派到消费组内的消费者来实现，这样每个分区仅仅被该消费组内的恰好一个消费者消费。这样，kafka确保指定消费者是指定分区的唯一消费者，并且按顺序消费数据。由于有多个分区，这样做仍然可以在多个消费者实例上负载均衡。注意一个消费组里的消费者实例不能超过主题的分区数。

### kafka作为存储系统
任何允许发布消息和消费消息两个过程解耦的消息队列实际上都充当正在传输的消息的存储系统。Kafka就是一个非常优秀的存储系统。
写到Kafka的信息被写到了磁盘，为了容错进行了复制。Kafka为生产者提供确认机制，这样直到数据被全部复制成功后，一个写操作才被认为成功，并且保证即时服务器写入失败也会持续运行。
Kafka使用的磁盘结构很容易扩展-无论服务器上有50KB还是50TB的持久化数据，Kafka做的事情是一样的。

由于对很好地利用存储，并且允许客户端来控制自身的读取位置，所以将Kafka当做某种特殊用途的分布式文件系统，致力于解决高性能、低延迟的提交日志存储，复制和传播特性。

###kafka作为流处理系统
Kafka不仅仅可以用来读、写、存储数据流、还是可以当做实时流处理系统。
Kafka中，流处理器是从输入主题中获取连续数据流，然后对输入数据做一些处理，接着产生连续数据流到输出主题的任何东西。
如，一个零售程序接收销售和货物的输入数据流，然后计算后产生排序和价格调整的输出流。

如果是直接做一些简单的处理过程可以通过producer和consumer的API，对于更复杂的转换，Kafka提供了一套完整集成的流API，允许对流进行计算聚合或者合并流数据。

这套API帮助解决了这些难题：处理无序数据，重复处理数据，执行状态有关的计算等。
这套API构建与Kafka提供的核心原是愈发：生产者消费者API，Kafka的有状态存储机制，在流处理器实例之间使用相同的group组机制进行容错

### 总结

Kafka包含了消息、存储、流处理这些特性看似不寻常，但是Kafka作为一个流平台这些都是必须的。
分布式文件系统如HDFS允许存储静态文件用来批处理。这样的系统实际上可以存储并处理过去的历史数据。

传统企业级消息系统让你可以处理在订阅之后产生的数据，而构建于分布式文件系统的系统则可以处理订阅之前的数据。
Kafka拥有这两种特性，这对于Kafka作为流程序平台和流数据流水线至关重要

通过结合了存储和低延迟订阅的特性，流式应用程序以同样的方式处理过去和未来的数据。这个单一的程序可以处理历史的、已存储的数据；当消费到最后一条数据时，并没有结束，可以继续处理未来产生的数据。这便是流处理的一个广义概念，包括了批处理和消息驱动程序。

同样，对于流水局流水线而言，订阅和实时事件相结合使借助Kafka作为非常低延迟的流水线成为可能；可靠存储数据的特性使其应用于传送关键数据的场合，这些场合对于数据的传递必须得到保证，或者用于和仅仅周期性加载数据或可以长时间进行维护的离线系统进行集成的场景。Kafka流处理设施使得可以在数据到达时变换数据。
